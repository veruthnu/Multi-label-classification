{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "divided-consultation",
   "metadata": {},
   "source": [
    "# Training process\n",
    "\n",
    "\n",
    "* Resnet 을 기본으로 함\n",
    "* 첫번째 필터의 필터사이즈를 7 -> 10 \n",
    "* BN 과 dropout을 같이 사용해봄 \n",
    "* 훈련데이터셋을 datagen.flow 로 두배증식후 다시 imagedatagenerator 사용 \n",
    "* LR 0.003 훈련중 saddle point 에 들어선거 같아 벗어나기 위해 0.05로 변경 (Loss 더 상승)\n",
    "* 다시 LR 0.003로 변경함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "black-storage",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "from tensorflow.keras import Sequential, models, layers\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Activation, BatchNormalization, AveragePooling2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from matplotlib.image import imread\n",
    "from cv2 import imread\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import imutils\n",
    "import zipfile\n",
    "\n",
    "seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "oriental-timing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "assisted-cassette",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adult-rainbow",
   "metadata": {},
   "outputs": [],
   "source": [
    "def macro_f1(y, y_hat, thresh=0.5):\n",
    "    \"\"\"Compute the macro F1-score on a batch of observations (average F1 across labels)\n",
    "\n",
    "    Args:\n",
    "        y (int32 Tensor): labels array of shape (BATCH_SIZE, N_LABELS)\n",
    "        y_hat (float32 Tensor): probability matrix from forward propagation of shape (BATCH_SIZE, N_LABELS)\n",
    "        thresh: probability value above which we predict positive\n",
    "\n",
    "    Returns:\n",
    "        macro_f1 (scalar Tensor): value of macro F1 for the batch\n",
    "    \"\"\"\n",
    "    y_pred = tf.cast(tf.greater(y_hat, thresh), tf.float32)\n",
    "    tp = tf.cast(tf.math.count_nonzero(y_pred * y, axis=0), tf.float32)\n",
    "    fp = tf.cast(tf.math.count_nonzero(y_pred * (1 - y), axis=0), tf.float32)\n",
    "    fn = tf.cast(tf.math.count_nonzero((1 - y_pred) * y, axis=0), tf.float32)\n",
    "    f1 = 2*tp / (2*tp + fn + fp + 1e-16)\n",
    "    macro_f1 = tf.reduce_mean(f1)\n",
    "    return macro_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "selective-watershed",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train_data.csv')\n",
    "validation_data = pd.read_csv('validation_data.csv')\n",
    "test_data = pd.read_csv('test_data.csv')\n",
    "target = pd.read_csv('data/dirty_mnist_2nd_answer.csv',index_col='index')\n",
    "target_names = target.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "provincial-underwear",
   "metadata": {},
   "outputs": [],
   "source": [
    "newtrain_data = pd.read_csv('newtrain.csv')\n",
    "newvalidation_data = pd.read_csv('newvalidation.csv')\n",
    "test_data = pd.read_csv('test_data.csv')\n",
    "newtarget = pd.read_csv('data/newTarget.csv',index_col='index')\n",
    "target_names = newtarget.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "genuine-helena",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = .003 # Keep it small when transfer learning\n",
    "EPOCHS = 300\n",
    "IMG_SIZE = 256 # Specify height and width of image to match the input format of the model\n",
    "CHANNELS = 1 # Keep RGB color channels to match the input format of the model\n",
    "# CHANNELS change by 1 from 3\n",
    "N_LABELS = 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bigger-moscow",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 48\n",
    "#BATCH_SIZE = 256 # Big enough to measure an F1-score\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE # Adapt preprocessing and prefetching dynamically to reduce GPU and CPU idle time\n",
    "SHUFFLE_BUFFER_SIZE = 1024 # Shuffle the training data by a chunck of 1024 observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "hundred-combination",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 80000 validated image filenames.\n",
      "Found 20000 validated image filenames.\n",
      "Found 5000 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "# 정규화변경 featurewise_std_normalization = True 로\n",
    "\n",
    "generator = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "   \n",
    "    \n",
    "    rescale=1./255, \n",
    "    \n",
    "    rotation_range=90,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='constant',\n",
    "    cval = 0)\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    newtrain_data,\n",
    "    'data/train_dirty_mnist_2nd/',\n",
    "    x_col='filename',\n",
    "    y_col=list(newtrain_data.columns[1:]),\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    class_mode='raw',\n",
    "    color_mode='grayscale',\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "validation_generator = generator.flow_from_dataframe(\n",
    "    newvalidation_data,\n",
    "    'data/train_dirty_mnist_2nd/',\n",
    "    x_col='filename',\n",
    "    y_col=list(newvalidation_data.columns[1:]),\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    class_mode='raw',\n",
    "    color_mode='grayscale',\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "test_generator = generator.flow_from_dataframe(\n",
    "    test_data,\n",
    "    'data/test_dirty_mnist_2nd/',\n",
    "    x_col='filename',\n",
    "    y_col=None,\n",
    "    class_mode=None,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    color_mode='grayscale',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fluid-canadian",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-8-46fc650e7766>, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-8-46fc650e7766>\"\u001b[1;36m, line \u001b[1;32m10\u001b[0m\n\u001b[1;33m    horizontal_flip=True,\u001b[0m\n\u001b[1;37m                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    vertical_flip= True,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='constant',\n",
    "    cval = 1)\n",
    "\n",
    "img = load_img('data/train_dirty_mnist_2nd/00000.png')  # PIL 이미지\n",
    "x = img_to_array(img)  # (3, 150, 150) 크기의 NumPy 배열\n",
    "x = x.reshape((1,) + x.shape)  # (1, 3, 150, 150) 크기의 NumPy 배열\n",
    "\n",
    "# 아래 .flow() 함수는 임의 변환된 이미지를 배치 단위로 생성해서\n",
    "# 지정된 preview/ 폴더에 저장합니다.\n",
    "i = 0\n",
    "for batch in datagen.flow(x, batch_size=1,\n",
    "                          save_to_dir='preview_update', save_prefix='emnist', save_format='jpeg'):\n",
    "    i += 1\n",
    "    if i > 20:\n",
    "        break  # 이미지 20장을 생성하고 마칩니다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fantastic-costume",
   "metadata": {},
   "source": [
    "# wresV7(normal resnet, filter16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informational-declaration",
   "metadata": {},
   "source": [
    "* 모델을 단순화 해서 피팅하려면 어떻게 해야할까?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saving-egyptian",
   "metadata": {},
   "source": [
    "* 0213 edit - augmentation (val_loss = 0.5791) \n",
    "* 0214 edit - 첫번째 레이어의 필터의 크기를 늘려 10 by 10 stride 2좀더 큰 패턴을 찾아봄\n",
    "* 0214 edit - 데이터의 분포가 중심에 몰려있어 첫 레이어에서 패딩을 하지않음 (val_loss = 0.38) 점수 0.78\n",
    "* 0214 edit - 첫번째 필터 10,10 stride 2 & 각레이어 세번째 마다 dropout(.2) 추가 (val_loss = 0.35) 점수 0.81\n",
    "* 0218 edit - 첫번째 필터 16,16 stride 2 (val_loss = 0.31) 점수 0.80\n",
    "* 0219 edit - 5층 제거 후 마지막층 filter 512 로 변경\n",
    "* 0221 edit - 첫층 필터 64 -> 256 , 드랍아웃 0.8\n",
    "* 0225 edit - BN 삭제\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "transsexual-expression",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.layers import BatchNormalization, Conv2D, Activation, Dense, GlobalAveragePooling2D, MaxPooling2D, ZeroPadding2D, Add\n",
    "from tensorflow.keras.layers import AveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model, load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "nutritional-translation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of classes\n",
    "K = 26\n",
    " \n",
    " \n",
    "input_tensor = Input(shape=(256, 256, 1), dtype='float32', name='input')\n",
    " \n",
    " \n",
    "def conv1_layer(x):    \n",
    "    # og - x = Conv2D(64, (10, 10), strides=(2, 2))(x)\n",
    "    x = Conv2D(64, (10, 10), strides=(2, 2))(x) # edit 0221\n",
    "    \n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    x = Activation('relu')(x)\n",
    "    #x = Dropout(.6)(x) #edit 0221\n",
    "    \n",
    "    return x   \n",
    " \n",
    "    \n",
    "    \n",
    "def conv2_layer(x):         \n",
    "    x = MaxPooling2D((3, 3), 2)(x)     \n",
    " \n",
    "    shortcut = x\n",
    " \n",
    "    for i in range(3):\n",
    "        if (i == 0):\n",
    "            x = Conv2D(64, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            x = Conv2D(64, (3, 3), strides=(1, 1), padding='same')(x)\n",
    "            \n",
    "            x = BatchNormalization()(x)\n",
    "            \n",
    "            x = Activation('relu')(x)\n",
    " \n",
    "            x = Conv2D(256, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            shortcut = Conv2D(256, (1, 1), strides=(1, 1), padding='valid')(shortcut)  \n",
    "        \n",
    "            x = BatchNormalization()(x)\n",
    "            shortcut = BatchNormalization()(shortcut)\n",
    " \n",
    "            x = Add()([x, shortcut])\n",
    "            x = Activation('relu')(x)\n",
    "       \n",
    "        \n",
    "            \n",
    "            shortcut = x\n",
    " \n",
    "        else:\n",
    "            x = Conv2D(64, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            \n",
    "            x = BatchNormalization()(x)\n",
    "            \n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            x = Conv2D(64, (3, 3), strides=(1, 1), padding='same')(x)\n",
    "            \n",
    "            x = BatchNormalization()(x)\n",
    "            \n",
    "            x = Activation('relu')(x)\n",
    " \n",
    "            x = Conv2D(256, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "    \n",
    "            x = BatchNormalization()(x)            \n",
    " \n",
    "            x = Add()([x, shortcut])   \n",
    "            x = Activation('relu')(x)  \n",
    "            \n",
    "            \n",
    "            shortcut = x        \n",
    "    \n",
    "    return x\n",
    " \n",
    " \n",
    " \n",
    "def conv3_layer(x):        \n",
    "    shortcut = x    \n",
    "    \n",
    "    for i in range(4):     \n",
    "        if(i == 0):            \n",
    "            x = Conv2D(128, (1, 1), strides=(2, 2), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)        \n",
    "            \n",
    "            x = Conv2D(128, (3, 3), strides=(1, 1), padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)  \n",
    " \n",
    "            x = Conv2D(512, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            shortcut = Conv2D(512, (1, 1), strides=(2, 2), padding='valid')(shortcut)\n",
    "            x = BatchNormalization()(x)\n",
    "            shortcut = BatchNormalization()(shortcut)            \n",
    " \n",
    "            x = Add()([x, shortcut])    \n",
    "            x = Activation('relu')(x)    \n",
    "           \n",
    "            \n",
    "            shortcut = x              \n",
    "        \n",
    "        else:\n",
    "            x = Conv2D(128, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            x = Conv2D(128, (3, 3), strides=(1, 1), padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    " \n",
    "            x = Conv2D(512, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)            \n",
    " \n",
    "            x = Add()([x, shortcut])     \n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            \n",
    "            shortcut = x      \n",
    "            \n",
    "    return x\n",
    " \n",
    "\n",
    "def conv3_layer_exdrop(x):        \n",
    "    shortcut = x    \n",
    "    \n",
    "    for i in range(4):     \n",
    "        if(i == 0):            \n",
    "            x = Conv2D(128, (1, 1), strides=(2, 2), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)        \n",
    "            \n",
    "            x = Conv2D(128, (3, 3), strides=(1, 1), padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)  \n",
    " \n",
    "            x = Conv2D(512, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            shortcut = Conv2D(512, (1, 1), strides=(2, 2), padding='valid')(shortcut)\n",
    "            x = BatchNormalization()(x)\n",
    "            shortcut = BatchNormalization()(shortcut)            \n",
    " \n",
    "            x = Add()([x, shortcut])    \n",
    "            x = Activation('relu')(x)    \n",
    "           \n",
    "            \n",
    "            shortcut = x              \n",
    "        \n",
    "        else:\n",
    "            x = Conv2D(128, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            x = Conv2D(128, (3, 3), strides=(1, 1), padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    " \n",
    "            x = Conv2D(512, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)            \n",
    " \n",
    "            x = Add()([x, shortcut])     \n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            \n",
    "            shortcut = x      \n",
    "            \n",
    "    return x\n",
    "     \n",
    "    \n",
    " \n",
    "def conv4_layer(x):\n",
    "    shortcut = x        \n",
    "  \n",
    "    for i in range(6):     \n",
    "        if(i == 0):            \n",
    "            x = Conv2D(256, (1, 1), strides=(2, 2), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)        \n",
    "            \n",
    "            x = Conv2D(256, (3, 3), strides=(1, 1), padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)  \n",
    " \n",
    "            x = Conv2D(512, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            shortcut = Conv2D(512, (1, 1), strides=(2, 2), padding='valid')(shortcut)\n",
    "            x = BatchNormalization()(x)\n",
    "            shortcut = BatchNormalization()(shortcut)\n",
    " \n",
    "            x = Add()([x, shortcut]) \n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            \n",
    "            shortcut = x               \n",
    "        \n",
    "        else:\n",
    "            x = Conv2D(256, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            x = Conv2D(256, (3, 3), strides=(1, 1), padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    " \n",
    "            x = Conv2D(512, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)            \n",
    " \n",
    "            x = Add()([x, shortcut])    \n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            \n",
    "            shortcut = x      \n",
    " \n",
    "    return x\n",
    " \n",
    "def conv5_layer(x):\n",
    "    shortcut = x        \n",
    "  \n",
    "    for i in range(6): \n",
    "        if(i == 0):            \n",
    "            x = Conv2D(256, (1, 1), strides=(2, 2), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)        \n",
    "            \n",
    "            x = Conv2D(256, (3, 3), strides=(1, 1), padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)  \n",
    " \n",
    "            x = Conv2D(512, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            shortcut = Conv2D(512, (1, 1), strides=(2, 2), padding='valid')(shortcut)\n",
    "            x = BatchNormalization()(x)\n",
    "            shortcut = BatchNormalization()(shortcut)\n",
    " \n",
    "            x = Add()([x, shortcut]) \n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            \n",
    "            shortcut = x               \n",
    "        \n",
    "        else:\n",
    "            x = Conv2D(256, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            x = Conv2D(256, (3, 3), strides=(1, 1), padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    " \n",
    "            x = Conv2D(512, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)            \n",
    " \n",
    "            x = Add()([x, shortcut])    \n",
    "            x = Activation('relu')(x)\n",
    "           \n",
    "            \n",
    "            shortcut = x      \n",
    " \n",
    "    return x\n",
    " \n",
    "def conv6_layer(x):\n",
    "    shortcut = x        \n",
    "  \n",
    "    for i in range(6):     \n",
    "        if(i == 0):            \n",
    "            x = Conv2D(256, (1, 1), strides=(2, 2), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)        \n",
    "            \n",
    "            x = Conv2D(256, (3, 3), strides=(1, 1), padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)  \n",
    " \n",
    "            x = Conv2D(512, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            shortcut = Conv2D(512, (1, 1), strides=(2, 2), padding='valid')(shortcut)\n",
    "            x = BatchNormalization()(x)\n",
    "            shortcut = BatchNormalization()(shortcut)\n",
    " \n",
    "            x = Add()([x, shortcut]) \n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            \n",
    "            shortcut = x               \n",
    "        \n",
    "        else:\n",
    "            x = Conv2D(256, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            x = Conv2D(256, (3, 3), strides=(1, 1), padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    " \n",
    "            x = Conv2D(512, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)            \n",
    " \n",
    "            x = Add()([x, shortcut])    \n",
    "            x = Activation('relu')(x)\n",
    "           \n",
    "            \n",
    "            shortcut = x      \n",
    " \n",
    "    return x\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    " \n",
    "x = conv1_layer(input_tensor)\n",
    "x = conv2_layer(x)\n",
    "x = conv3_layer(x)\n",
    "#x = conv3_layer_exdrop(x)\n",
    "x = conv4_layer(x)\n",
    "x = conv5_layer(x)\n",
    "#x = conv6_layer(x)\n",
    "\n",
    "\n",
    " \n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "output_tensor = Dense(K, activation='sigmoid')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "human-mystery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, 256, 256, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 124, 124, 64) 6464        input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 124, 124, 64) 256         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 124, 124, 64) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 61, 61, 64)   0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 61, 61, 64)   4160        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 61, 61, 64)   256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 61, 61, 64)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 61, 61, 64)   36928       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 61, 61, 64)   256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 61, 61, 64)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 61, 61, 256)  16640       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 61, 61, 256)  16640       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 61, 61, 256)  1024        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 61, 61, 256)  1024        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 61, 61, 256)  0           batch_normalization_3[0][0]      \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 61, 61, 256)  0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 61, 61, 64)   16448       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 61, 61, 64)   256         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 61, 61, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 61, 61, 64)   36928       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 61, 61, 64)   256         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 61, 61, 64)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 61, 61, 256)  16640       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 61, 61, 256)  1024        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 61, 61, 256)  0           batch_normalization_7[0][0]      \n",
      "                                                                 activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 61, 61, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 61, 61, 64)   16448       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 61, 61, 64)   256         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 61, 61, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 61, 61, 64)   36928       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 61, 61, 64)   256         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 61, 61, 64)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 61, 61, 256)  16640       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 61, 61, 256)  1024        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 61, 61, 256)  0           batch_normalization_10[0][0]     \n",
      "                                                                 activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 61, 61, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 31, 31, 128)  32896       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 31, 31, 128)  512         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 31, 31, 128)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 31, 31, 128)  147584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 31, 31, 128)  512         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 31, 31, 128)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 31, 31, 512)  66048       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 31, 31, 512)  131584      activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 31, 31, 512)  2048        conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 31, 31, 512)  2048        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 31, 31, 512)  0           batch_normalization_13[0][0]     \n",
      "                                                                 batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 31, 31, 512)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 31, 31, 128)  65664       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 31, 31, 128)  512         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 31, 31, 128)  0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 31, 31, 128)  147584      activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 31, 31, 128)  512         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 31, 31, 128)  0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 31, 31, 512)  66048       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 31, 31, 512)  2048        conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 31, 31, 512)  0           batch_normalization_17[0][0]     \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 31, 31, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 31, 31, 128)  65664       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 31, 31, 128)  512         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 31, 31, 128)  0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 31, 31, 128)  147584      activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 31, 31, 128)  512         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 31, 31, 128)  0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 31, 31, 512)  66048       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 31, 31, 512)  2048        conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 31, 31, 512)  0           batch_normalization_20[0][0]     \n",
      "                                                                 activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 31, 31, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 31, 31, 128)  65664       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 31, 31, 128)  512         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 31, 31, 128)  0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 31, 31, 128)  147584      activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 31, 31, 128)  512         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 31, 31, 128)  0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 31, 31, 512)  66048       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 31, 31, 512)  2048        conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 31, 31, 512)  0           batch_normalization_23[0][0]     \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 31, 31, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 16, 16, 256)  131328      activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 16, 16, 256)  1024        conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 16, 16, 256)  0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 16, 16, 256)  590080      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 16, 16, 256)  1024        conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 16, 16, 256)  0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 16, 16, 512)  131584      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 16, 16, 512)  262656      activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 16, 16, 512)  2048        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 16, 16, 512)  2048        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 16, 16, 512)  0           batch_normalization_26[0][0]     \n",
      "                                                                 batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 16, 16, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 16, 16, 256)  131328      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 16, 16, 256)  1024        conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 16, 16, 256)  0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 16, 16, 256)  590080      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 16, 16, 256)  1024        conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 16, 16, 256)  0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 16, 16, 512)  131584      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 16, 16, 512)  2048        conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 16, 16, 512)  0           batch_normalization_30[0][0]     \n",
      "                                                                 activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 16, 16, 512)  0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 16, 16, 256)  131328      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 16, 16, 256)  1024        conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 16, 16, 256)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 16, 16, 256)  590080      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 16, 16, 256)  1024        conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 16, 16, 256)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 16, 16, 512)  131584      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 16, 16, 512)  2048        conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 16, 16, 512)  0           batch_normalization_33[0][0]     \n",
      "                                                                 activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 16, 16, 512)  0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 16, 16, 256)  131328      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 16, 16, 256)  1024        conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 16, 16, 256)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 16, 16, 256)  590080      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 16, 16, 256)  1024        conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 16, 16, 256)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 16, 16, 512)  131584      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 16, 16, 512)  2048        conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 16, 16, 512)  0           batch_normalization_36[0][0]     \n",
      "                                                                 activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 16, 16, 512)  0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 16, 16, 256)  131328      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 16, 16, 256)  1024        conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 16, 16, 256)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 16, 16, 256)  590080      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 16, 16, 256)  1024        conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 16, 16, 256)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 16, 16, 512)  131584      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 16, 16, 512)  2048        conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 16, 16, 512)  0           batch_normalization_39[0][0]     \n",
      "                                                                 activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 16, 16, 512)  0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 16, 16, 256)  131328      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 16, 16, 256)  1024        conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 16, 16, 256)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 16, 16, 256)  590080      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 16, 16, 256)  1024        conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 16, 16, 256)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 16, 16, 512)  131584      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 16, 16, 512)  2048        conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 16, 16, 512)  0           batch_normalization_42[0][0]     \n",
      "                                                                 activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 16, 16, 512)  0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 8, 8, 256)    131328      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 8, 8, 256)    1024        conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 8, 8, 256)    0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 8, 8, 256)    590080      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 8, 8, 256)    1024        conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 8, 8, 256)    0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 8, 8, 512)    131584      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 8, 8, 512)    262656      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 8, 8, 512)    2048        conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 8, 8, 512)    2048        conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 8, 8, 512)    0           batch_normalization_45[0][0]     \n",
      "                                                                 batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 8, 8, 512)    0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 8, 8, 256)    131328      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 8, 8, 256)    1024        conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 8, 8, 256)    0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 8, 8, 256)    590080      activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 8, 8, 256)    1024        conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 8, 8, 256)    0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 8, 8, 512)    131584      activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 8, 8, 512)    2048        conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 8, 8, 512)    0           batch_normalization_49[0][0]     \n",
      "                                                                 activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 8, 8, 512)    0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 8, 8, 256)    131328      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 8, 8, 256)    1024        conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 8, 8, 256)    0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 8, 8, 256)    590080      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 8, 8, 256)    1024        conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 8, 8, 256)    0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 8, 8, 512)    131584      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 8, 8, 512)    2048        conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 8, 8, 512)    0           batch_normalization_52[0][0]     \n",
      "                                                                 activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 8, 8, 512)    0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 8, 8, 256)    131328      activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 8, 8, 256)    1024        conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 8, 8, 256)    0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 8, 8, 256)    590080      activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 8, 8, 256)    1024        conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 8, 8, 256)    0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 8, 8, 512)    131584      activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 8, 8, 512)    2048        conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 8, 8, 512)    0           batch_normalization_55[0][0]     \n",
      "                                                                 activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 8, 8, 512)    0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 8, 8, 256)    131328      activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 8, 8, 256)    1024        conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 8, 8, 256)    0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 8, 8, 256)    590080      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 8, 8, 256)    1024        conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 8, 8, 256)    0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 8, 8, 512)    131584      activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 8, 8, 512)    2048        conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 8, 8, 512)    0           batch_normalization_58[0][0]     \n",
      "                                                                 activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 8, 8, 512)    0           add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 8, 8, 256)    131328      activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 8, 8, 256)    1024        conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 8, 8, 256)    0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 8, 8, 256)    590080      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 8, 8, 256)    1024        conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 8, 8, 256)    0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 8, 8, 512)    131584      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 8, 8, 512)    2048        conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 8, 8, 512)    0           batch_normalization_61[0][0]     \n",
      "                                                                 activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 8, 8, 512)    0           add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 512)          0           activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1024)         525312      global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 1024)         4096        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 26)           26650       batch_normalization_62[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 12,827,610\n",
      "Trainable params: 12,788,826\n",
      "Non-trainable params: 38,784\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Wlayer = Model(input_tensor, output_tensor)\n",
    "Wlayer.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caroline-westminster",
   "metadata": {},
   "source": [
    "# Load savedmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "jewish-regulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "Wlayer.load_weights('Mnistmodel/resNoBN_15-0.2763.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impaired-combat",
   "metadata": {},
   "source": [
    "# Complie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "instrumental-nashville",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LR = 0.003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "serial-scout",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = './Mnistmodel/'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)\n",
    "\n",
    "modelpath = './Mnistmodel/resNoBN_{epoch:02d}-{val_loss:.4f}.h5'\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss',\n",
    "                              verbose=1, save_best_only=True)\n",
    "\n",
    "stop = EarlyStopping(patience=100)\n",
    "\n",
    "callbacks = [stop, checkpointer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "graphic-survival",
   "metadata": {},
   "outputs": [],
   "source": [
    "Wlayer.compile(loss='binary_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=LR),\n",
    "              metrics=[macro_f1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rough-springfield",
   "metadata": {},
   "source": [
    "# Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "waiting-aruba",
   "metadata": {},
   "source": [
    "* 지금 모델에서 단순화해서 테스트셋에 피팅 하려면 어떻게 해야할까"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "informative-photographer",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1876: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1667/1667 [==============================] - 504s 292ms/step - loss: 0.3097 - macro_f1: 0.8423 - val_loss: 0.3321 - val_macro_f1: 0.8417\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.33207, saving model to ./Mnistmodel\\resNoBN_01-0.3321.h5\n",
      "Epoch 2/300\n",
      "1667/1667 [==============================] - 478s 287ms/step - loss: 0.3078 - macro_f1: 0.8432 - val_loss: 0.2838 - val_macro_f1: 0.8680\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.33207 to 0.28384, saving model to ./Mnistmodel\\resNoBN_02-0.2838.h5\n",
      "Epoch 3/300\n",
      "1667/1667 [==============================] - 480s 288ms/step - loss: 0.3062 - macro_f1: 0.8448 - val_loss: 0.2730 - val_macro_f1: 0.8739\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.28384 to 0.27296, saving model to ./Mnistmodel\\resNoBN_03-0.2730.h5\n",
      "Epoch 4/300\n",
      "1667/1667 [==============================] - 493s 296ms/step - loss: 0.3053 - macro_f1: 0.8452 - val_loss: 0.2932 - val_macro_f1: 0.8687\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.27296\n",
      "Epoch 5/300\n",
      "1667/1667 [==============================] - 459s 276ms/step - loss: 0.3040 - macro_f1: 0.8461 - val_loss: 0.2752 - val_macro_f1: 0.8745\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.27296\n",
      "Epoch 6/300\n",
      "1667/1667 [==============================] - 454s 272ms/step - loss: 0.3022 - macro_f1: 0.8471 - val_loss: 0.2956 - val_macro_f1: 0.8644\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.27296\n",
      "Epoch 7/300\n",
      "1667/1667 [==============================] - 472s 283ms/step - loss: 0.2999 - macro_f1: 0.8486 - val_loss: 0.2805 - val_macro_f1: 0.8713\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.27296\n",
      "Epoch 8/300\n",
      "1667/1667 [==============================] - 476s 286ms/step - loss: 0.3004 - macro_f1: 0.8488 - val_loss: 0.2791 - val_macro_f1: 0.8726\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.27296\n",
      "Epoch 9/300\n",
      "1667/1667 [==============================] - 479s 288ms/step - loss: 0.2969 - macro_f1: 0.8506 - val_loss: 0.2802 - val_macro_f1: 0.8729\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.27296\n",
      "Epoch 10/300\n",
      "1667/1667 [==============================] - 489s 293ms/step - loss: 0.2967 - macro_f1: 0.8505 - val_loss: 0.2883 - val_macro_f1: 0.8657\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.27296\n",
      "Epoch 11/300\n",
      "1667/1667 [==============================] - 509s 305ms/step - loss: 0.2962 - macro_f1: 0.8513 - val_loss: 0.2805 - val_macro_f1: 0.8729\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.27296\n",
      "Epoch 12/300\n",
      "1667/1667 [==============================] - 494s 296ms/step - loss: 0.2933 - macro_f1: 0.8530 - val_loss: 0.2942 - val_macro_f1: 0.8654\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.27296\n",
      "Epoch 13/300\n",
      "1667/1667 [==============================] - 472s 283ms/step - loss: 0.2918 - macro_f1: 0.8541 - val_loss: 0.3160 - val_macro_f1: 0.8556\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.27296\n",
      "Epoch 14/300\n",
      "1667/1667 [==============================] - 483s 290ms/step - loss: 0.2903 - macro_f1: 0.8547 - val_loss: 0.2755 - val_macro_f1: 0.8732\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.27296\n",
      "Epoch 15/300\n",
      "1667/1667 [==============================] - 511s 306ms/step - loss: 0.2898 - macro_f1: 0.8551 - val_loss: 0.2744 - val_macro_f1: 0.8756\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.27296\n",
      "Epoch 16/300\n",
      "1667/1667 [==============================] - 506s 303ms/step - loss: 0.2876 - macro_f1: 0.8568 - val_loss: 0.2660 - val_macro_f1: 0.8778\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.27296 to 0.26597, saving model to ./Mnistmodel\\resNoBN_16-0.2660.h5\n",
      "Epoch 17/300\n",
      "1667/1667 [==============================] - 494s 296ms/step - loss: 0.2875 - macro_f1: 0.8565 - val_loss: 0.3054 - val_macro_f1: 0.8603\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.26597\n",
      "Epoch 18/300\n",
      "1667/1667 [==============================] - 490s 294ms/step - loss: 0.2863 - macro_f1: 0.8570 - val_loss: 0.2846 - val_macro_f1: 0.8723\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.26597\n",
      "Epoch 19/300\n",
      "1667/1667 [==============================] - 500s 300ms/step - loss: 0.2828 - macro_f1: 0.8594 - val_loss: 0.2820 - val_macro_f1: 0.8719\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.26597\n",
      "Epoch 20/300\n",
      "1667/1667 [==============================] - 489s 294ms/step - loss: 0.2835 - macro_f1: 0.8590 - val_loss: 0.2722 - val_macro_f1: 0.8776\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.26597\n",
      "Epoch 21/300\n",
      "1667/1667 [==============================] - 499s 299ms/step - loss: 0.2822 - macro_f1: 0.8599 - val_loss: 0.2955 - val_macro_f1: 0.8663\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.26597\n",
      "Epoch 22/300\n",
      "1667/1667 [==============================] - 497s 298ms/step - loss: 0.2802 - macro_f1: 0.8612 - val_loss: 0.2785 - val_macro_f1: 0.8756\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.26597\n",
      "Epoch 23/300\n",
      "1667/1667 [==============================] - 479s 287ms/step - loss: 0.2791 - macro_f1: 0.8616 - val_loss: 0.2782 - val_macro_f1: 0.8764\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.26597\n",
      "Epoch 24/300\n",
      "1667/1667 [==============================] - 503s 302ms/step - loss: 0.2760 - macro_f1: 0.8635 - val_loss: 0.3042 - val_macro_f1: 0.8619\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.26597\n",
      "Epoch 25/300\n",
      "1667/1667 [==============================] - 504s 302ms/step - loss: 0.2766 - macro_f1: 0.8634 - val_loss: 0.2773 - val_macro_f1: 0.8761\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.26597\n",
      "Epoch 26/300\n",
      "  16/1667 [..............................] - ETA: 7:00 - loss: 0.2721 - macro_f1: 0.8638"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-26e2e8eed6b5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m history = Wlayer.fit_generator(train_generator, epochs=EPOCHS,\n\u001b[1;32m----> 2\u001b[1;33m                               \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m                               )\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1891\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1892\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1893\u001b[1;33m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1895\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1130\u001b[0m                 _r=1):\n\u001b[0;32m   1131\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1132\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1133\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    795\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    796\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 797\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    798\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    799\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    823\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    824\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 825\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    826\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2970\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   2971\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 2972\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   2973\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2974\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1946\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1947\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1948\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1949\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1950\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    559\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    562\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = Wlayer.fit_generator(train_generator, epochs=EPOCHS,\n",
    "                              validation_data=validation_generator, callbacks=callbacks,shuffle=True\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "worst-hierarchy",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417/417 [==============================] - 36s 85ms/step - loss: 0.2824 - macro_f1: 0.8664\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2823958396911621, 0.8664236068725586]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Wlayer.evaluate(validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "filled-details",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1937: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "predict = Wlayer.predict_generator(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "warming-sending",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.DataFrame(predict, columns=newtarget.columns)\n",
    "submission = pd.read_csv('data/sample_submission.csv')\n",
    "\n",
    "for i in submit.columns:\n",
    "    for j in range(len(submit)):\n",
    "        if submit[i][j] > 0.5:\n",
    "            submit[i][j] = int(1)\n",
    "        else:\n",
    "            submit[i][j] = int(0)\n",
    "\n",
    "\n",
    "submission = pd.DataFrame(submission['index'])\n",
    "for i in submit.columns:\n",
    "    submission[i] = submit[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "accredited-newspaper",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission03013.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "steady-great",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "      <th>f</th>\n",
       "      <th>g</th>\n",
       "      <th>h</th>\n",
       "      <th>i</th>\n",
       "      <th>...</th>\n",
       "      <th>q</th>\n",
       "      <th>r</th>\n",
       "      <th>s</th>\n",
       "      <th>t</th>\n",
       "      <th>u</th>\n",
       "      <th>v</th>\n",
       "      <th>w</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50003</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index    a    b    c    d    e    f    g    h    i  ...    q    r    s  \\\n",
       "0  50000  1.0  0.0  1.0  0.0  1.0  1.0  0.0  1.0  1.0  ...  0.0  0.0  0.0   \n",
       "1  50001  0.0  1.0  1.0  0.0  1.0  0.0  0.0  0.0  1.0  ...  0.0  1.0  0.0   \n",
       "2  50002  0.0  0.0  1.0  1.0  1.0  0.0  1.0  0.0  1.0  ...  1.0  1.0  1.0   \n",
       "3  50003  1.0  1.0  0.0  0.0  1.0  1.0  1.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "4  50004  0.0  0.0  1.0  0.0  1.0  1.0  0.0  0.0  0.0  ...  1.0  0.0  1.0   \n",
       "\n",
       "     t    u    v    w    x    y    z  \n",
       "0  1.0  1.0  1.0  0.0  1.0  0.0  0.0  \n",
       "1  0.0  0.0  1.0  0.0  0.0  1.0  0.0  \n",
       "2  0.0  1.0  0.0  1.0  0.0  0.0  1.0  \n",
       "3  0.0  0.0  1.0  0.0  1.0  0.0  1.0  \n",
       "4  1.0  0.0  0.0  1.0  0.0  1.0  0.0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "union-cotton",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.3302001953125"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.iloc[:,1:].sum(axis=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beneficial-kuwait",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
